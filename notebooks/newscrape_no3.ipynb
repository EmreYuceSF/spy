{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_dir = \"/Users/emreyuce/Library/Application Support/Google/Chrome/User Data\"\n",
    "\n",
    "# Options to specify the user profile\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(f\"user-data-dir={user_data_dir}\")\n",
    "options.add_argument(\"profile-directory=Default\")  # 'Default' is the default profile\n",
    "\n",
    "# Launch Chrome with your profile\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "\n",
    "# Login URL\n",
    "login_url = 'https://sso.accounts.dowjones.com/login-page?client_id=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO&redirect_uri=https%3A%2F%2Fwww.wsj.com%2Fclient%2Fauth&response_type=code&scope=openid%20idp_id%20roles%20tags%20email%20given_name%20family_name%20uuid%20djid%20djUsername%20djStatus%20trackid%20prts%20updated_at%20created_at%20offline_access&ui_locales=en-us-x-wsj-223-2&nonce=cdb92d13-ac4b-42a8-8d0a-948fa4ea0c1c&state=yNWtWfVzrx-k-VtM.4ge4KPFVs5H_hxxSzg9zDJ225bvbVOvT5x_aKxkoFY0&resource=https%253A%252F%252Fwww.wsj.com&protocol=oauth2&client=5hssEAdMy0mJTICnJNvC9TXEw3Va7jfO#/signin-password'\n",
    "driver.get(login_url)\n",
    "\n",
    "# WebDriverWait kullanarak elementlerin görünür olmasını bekle\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# Giriş sayfası yüklendikten sonra kullanıcı adı ve şifreyi gönder\n",
    "username = wait.until(EC.presence_of_element_located((By.ID, 'emailOrUsername')))\n",
    "password = wait.until(EC.presence_of_element_located((By.ID, 'password')))\n",
    "\n",
    "# Giriş bilgilerini gir\n",
    "username.send_keys('eyuce@mail.ccsf.edu')\n",
    "password.send_keys('Bin.98Seven!')\n",
    "\n",
    "# \"Sign In\" butonunu bul ve tıkla\n",
    "signin_button = wait.until(EC.element_to_be_clickable((By.ID, 'signin-pass-submit-btn')))\n",
    "signin_button.click()\n",
    "\n",
    "# Sayfanın yüklenmesini bekle\n",
    "time.sleep(1)\n",
    "\n",
    "# Click the continue button\n",
    "continue_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"inline-flex\")))\n",
    "continue_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Create an empty list to store article data\n",
    "article_data = []\n",
    "\n",
    "# Scraping articles in batches of 50 pages\n",
    "for i in range(1, 501, 50):  # Loop through pages in chunks of 50\n",
    "    for page in range(i, min(i + 50, 501)):  # Handle 50 pages in each batch, up to 500 pages\n",
    "        time.sleep(1)\n",
    "        # Open the news URL for the current page\n",
    "        news_url = f'https://www.wsj.com/search?query=us%20finance&isToggleOn=true&operator=OR&sort=relevance&duration=4y&startDate=2021%2F01%2F31&endDate=2025%2F01%2F31&meta=&source=wsjie%2Cwsjpro%2Clivecoverage%2Cwsjsitesrch&page={page}'\n",
    "        driver.get(news_url)\n",
    "\n",
    "        # Get the page content\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Process the page with BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Extract article headlines and dates\n",
    "        articles = soup.find_all('article', class_='WSJTheme--story--XB4V2mLz')\n",
    "\n",
    "        for article in articles:\n",
    "            headline = article.find('div', class_='WSJTheme--search-combined-headline-summary--1bmOvoTg')\n",
    "\n",
    "            # Extract date\n",
    "            date_container = article.find('div', class_='WSJTheme--search-combined-byline-timestamp--kmgehrO6')\n",
    "            date = date_container.find('p', class_='WSJTheme--timestamp--22sfkNDv') if date_container else None\n",
    "\n",
    "            # Store headline and date in the list\n",
    "            headline_text = headline.text.strip() if headline else \"Başlık bulunamadı.\"\n",
    "            date_text = date.text.strip() if date else \"Tarih bulunamadı.\"\n",
    "\n",
    "            article_data.append({\n",
    "                'Headline': headline_text,\n",
    "                'Date': date_text\n",
    "            })\n",
    "\n",
    "    # After scraping 50 pages, save the data to CSV\n",
    "    df_batch = pd.DataFrame(article_data)\n",
    "    df_batch.to_csv(f'wsj_articles_batch_{i}_{min(i + 49, 500)}.csv', index=False)\n",
    "\n",
    "# Combine all batches into one DataFrame\n",
    "df_combined = pd.concat([pd.read_csv(f'wsj_articles_batch_{i}_{min(i + 49, 500)}.csv') for i in range(1, 501, 50)], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a single CSV file\n",
    "df_combined.to_csv('wsj_articles_combined.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
